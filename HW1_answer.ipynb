{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW1_answer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMUA4wX6ZEBEbDqjUp1yrxz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gytjr8422/SOCAR-AI-BOOT-CAMP/blob/main/HW1_answer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HW1\n",
        "데이터셋의 크기가 1/10이 되었을때도 gradient descent를 이용한 linear regression이 잘 동작하는지 강의에서 배운 k-fold cross validation (k=5)을 활용해서 확인해보세요. \n",
        "그리고 데이터셋의 크기가 원래 사이즈였을 때도 똑같이 k-fold cross validation (k=5)를 진행해서 두 경우의 validation loss (k round의 평균 test loss)를 비교해보세요.\n",
        "\n",
        "###참고사항\n",
        "1.   위에 주어진 코드에서는 학습 방법에 초점이 맞춰져 test set이 따로 없었지만, 실제로 학습을 진행할때는 validation set이나 test set을 통해 성능을 확인하는 것이 필수적입니다!\n",
        "2.   전체 데이터를 k개의 부분집합으로 나누기 위해서 아래와 같은 sklearn 라이브러리의 KFold 클래스를 사용해도 되지만,\n",
        "```\n",
        "from sklearn.model_selection import KFold\n",
        "```\n",
        "연습을 위해서 Lab 1-1에서 배운 Slicing을 통해서 데이터셋을 k개로 나누고\n",
        "k round의 learning을 진행해주세요.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AcGfhhi1SuXf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tr4D93XDSlUx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9DS3dV9Sqza",
        "outputId": "eff9ee01-c32f-4529-8e4c-327d36f3cb7f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = open('/content/drive/MyDrive/Colab Notebooks/data/regression_data.txt','r')  # open the file with read-only\n",
        "text = file.readlines() # read all lines texts\n",
        "file.close() # close the file\n",
        "\n",
        "x_data = []\n",
        "y_data = []\n",
        "\n",
        "# convert to float\n",
        "for idx,s in enumerate(text):\n",
        "  if idx % 10 == 0:\n",
        "    data = s.split()\n",
        "    x_data.append(float(data[0]))\n",
        "    y_data.append(float(data[1]))\n",
        "\n",
        "x_data = np.asarray(x_data, dtype=np.float32)\n",
        "y_data = np.asarray(y_data, dtype=np.float32)"
      ],
      "metadata": {
        "id": "R-JZjjvGTBVn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot(x_data, y_data, 'ro') # plot data\n",
        "\n",
        "plt.xlabel('x-axis')\n",
        "plt.ylabel('-axis')\n",
        "plt.title('My data')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "HyNtRmh4Tt-U",
        "outputId": "f7b8dec2-4622-4e88-92ed-5bedebb64007"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAeOklEQVR4nO3dfbRddX3n8fcnwYARUZFbi+ThRg1TU+kEe8R2ZuEDhRofGhhxaZiLosMYUTN2hjoFJ9Zx0WZmxBZHbaZ6HQHBi0Fs1btUikWh1tZobkoECQsIwYQEKlcHH2jKQ/Qzf+x9zc7NucnZ4eyck3s/r7XOOmf/9t6/fHducj53P/5km4iIiE7N6nUBERFxeElwRERELQmOiIioJcERERG1JDgiIqKWBEdERNSS4IjoA5LeLOmbva4johMJjogDkPR9SY9JOm5S+y2SLGnwENfzfkmfPpR/ZkRVgiOiM/cC50xMSDoJmNu7ciJ6J8ER0ZmrgTdVps8DrpqYkPQiST+QNLvS9lpJ323XmaRnShqV9FNJ3wGeO2n+hyXdV87fKOnUsn0Z8N+AN0h6eKJ/SW+RdIekn0naKult3drwiMkSHBGdWQ8cI+n5ZTisAH55uMj2BuBHwO9W1nkjlXCZZC3wCHA88B/KV9UGYClwLHANcJ2ko2z/NfA/gGttH237X5fLPwi8BjgGeAvwIUkvPNiNjdifBEdE5yb2Os4A7gB2Tpr/KeBcAEnHAq+g+NLfSxk8ZwPvs/3Ptr9XrvtLtj9t+0e2d9v+M+BI4F9NVZjtL9u+x4W/Bb4KnHqQ2xmxX0f0uoCIw8jVwDeARbTfk/g0cIekpwCvB/7O9gNtlhug+L93X6VtW3UBSe8GzgeeDZhiT2Kvk/OTln8l8N+BEyl+IZwL3NbRVkXUlD2OiA7Z3kZxkvxVwF+1mb8T+BbwWorDVFdP0dU4sBuYX2lbMPGhPJ/xhxTh8wzbTwd+Amjij6p2JulI4C+BPwWeVS7/lcryEV2V4Iio53zgNNv/PMX8qyi+9E+iTbgA2P55Oe/9kuZKWkJxsn3CUymCZRw4QtL7KPY4JvwAGJQ08f93DsWhrHFgd7n3UT3XEtFVCY6IGsrzCGP7WeTzwELg87Z37We5VcDRwD8BVwJXVObdAPw1cBfFIaxH2Puw1nXl+48k/aPtnwHvAj4LPAT8e2C0022KqEsZyCmiuyTdA7zN9o29riWiCdnjiOgiSWdTnIP4eq9riWhKrqqK6BJJNwNLgDfa/kWPy4loTA5VRURELTlUFRERtcyIQ1XHHXecBwcHe11GRMRhZePGjT+0PTC5fUYEx+DgIGNj+7uCMiIiJpO0rV17DlVFREQtCY6IiKglwREREbUkOCIiopYER0RE1JLgiIiYbkZGYHAQZs0q3kdGutr9jLgcNyJixhgZgZUrYVf5cOZt24ppgKGhrvwR2eOIiJhOVq/eExoTdu0q2rskwRERMZ1s316v/SAkOCIippMFC+q1H4QER0TEdLJmDcydu3fb3LlFe5ckOCIippOhIRgehoULQSreh4e7dmIcclVVRMT0MzTU1aCYrNE9DknLJN0paYuki/ez3NmSLKlVaXtPud6dkl5Rt8+IiGhGY3sckmYDa4EzgB3ABkmjtjdPWu6pwO8D3660LQFWAL8OPBu4UdKJ5ewD9hkREc1pco/jFGCL7a22HwPWAWe2We6PgQ8Aj1TazgTW2X7U9r3AlrK/TvuMiIiGNBkcJwD3VaZ3lG2/JOmFwHzbX+5w3QP2Wel7paQxSWPj4+MHtwUREbGPnl1VJWkWcBnwB030b3vYdst2a2Bgn5EPIyLiIDV5VdVOYH5lel7ZNuGpwAuAmyUB/CowKmn5AdbdX58REdGwJvc4NgCLJS2SNIfiZPfoxEzbP7F9nO1B24PAemC57bFyuRWSjpS0CFgMfOdAfUZERPMa2+OwvVvSKuAGYDZwue3bJV0CjNme8gu/XO6zwGZgN/BO2z8HaNdnU9sQERH7ku1e19C4VqvlsbGxXpcREXFYkbTRdmtyex45EhERtSQ4IiKilgRHRETUkuCIiIhaEhwREVFLgiMiImpJcERERC0JjoiIqCXBERERtSQ4IiKilgRHRETUkuCIiIhaEhwREVFLgiMiImpJcERERC0JjoiIqKXR4JC0TNKdkrZIurjN/Ask3SZpk6RvSlpStg+VbROvX0haWs67uexzYt6vNLkNERGxt8aGjpU0G1gLnAHsADZIGrW9ubLYNbY/Vi6/HLgMWGZ7BBgp208CvmB7U2W9oXJs8oiIOMSa3OM4Bdhie6vtx4B1wJnVBWz/tDL5FKDdOLbnlOtGREQfaGyPAzgBuK8yvQN48eSFJL0TuBCYA5zWpp83MClwgCsk/Rz4S+BPPBMGTo+I6BM9Pzlue63t5wIXAe+tzpP0YmCX7e9VmodsnwScWr7e2K5fSSsljUkaGx8fb6j6iIiZp8ng2AnMr0zPK9umsg44a1LbCuAz1QbbO8v3nwHXUBwS24ftYdst262BgYGapUdExFSaDI4NwGJJiyTNoQiB0eoCkhZXJl8N3F2ZNwt4PZXzG5KOkHRc+flJwGuA6t5IRETvjIzA4CDMmlW8j4z0uqJGNHaOw/ZuSauAG4DZwOW2b5d0CTBmexRYJel04HHgIeC8ShcvAe6zvbXSdiRwQxkas4EbgU80tQ0RER0bGYGVK2HXrmJ627ZiGmBoqHd1NUAz4bxyq9Xy2Fiu3o2IBg0OFmEx2cKF8P3vH+pqukLSRtutye09PzkeETEtbN9er/0wluCIiOiGBQvqtR/GEhwREd2wZg3Mnbt329y5Rfs0k+CIiOiGoSEYHi7OaUjF+/DwtDsxDs3eOR4RMbMMDU3LoJgsexwREVFLgiMiImpJcERERC0JjoiIqCXBERERtSQ4IiKilgRHRETUkuCIiIhaEhwREVFLgiMiImpJcERERC2NBoekZZLulLRF0sVt5l8g6TZJmyR9U9KSsn1Q0r+U7Zskfayyzm+W62yR9BFJanIbIiJib40Fh6TZwFrglcAS4JyJYKi4xvZJtpcClwKXVebdY3tp+bqg0v4XwFuBxeVrWVPbEBER+2pyj+MUYIvtrbYfA9YBZ1YXsP3TyuRTgP2OYyvpeOAY2+tdjHl7FXBWd8uOiIj9aTI4TgDuq0zvKNv2Iumdku6h2ON4V2XWIkm3SPpbSadW+txxoD4jIqI5PT85bnut7ecCFwHvLZsfABbYPhm4ELhG0jF1+pW0UtKYpLHx8fHuFh0RMYM1GRw7gfmV6Xll21TWUR52sv2o7R+VnzcC9wAnluvP66RP28O2W7ZbAwMDB70RERGxtyaDYwOwWNIiSXOAFcBodQFJiyuTrwbuLtsHypPrSHoOxUnwrbYfAH4q6bfKq6neBHyxwW2IiIhJGhs61vZuSauAG4DZwOW2b5d0CTBmexRYJel04HHgIeC8cvWXAJdIehz4BXCB7f9XznsHcCXwZOD68hUREYeIiouTprdWq+WxsbFelxERcViRtNF2a3J7z0+OR0TE4SXBERERtSQ4IiKilgRHRETUkuCIiIhaEhwREVFLgiMiImpJcERERC0JjoiIqCXBERERtSQ4IiKilgRHRETUkuCIiIhaEhwREVFLgiMiImpJcERERC0JjoiIqKXR4JC0TNKdkrZIurjN/Ask3SZpk6RvSlpStp8haWM5b6Ok0yrr3Fz2ual8/UqT2xAREXtrbMxxSbOBtcAZwA5gg6RR25sri11j+2Pl8suBy4BlwA+B37N9v6QXUIxbfkJlvSHbGQs2IqIHmtzjOAXYYnur7ceAdcCZ1QVs/7Qy+RTAZfsttu8v228HnizpyAZrjYiIDjUZHCcA91Wmd7D3XgMAkt4p6R7gUuBdbfo5G/hH249W2q4oD1P9kSS1+8MlrZQ0JmlsfHz84LciIiL20vOT47bX2n4ucBHw3uo8Sb8OfAB4W6V5yPZJwKnl641T9Dtsu2W7NTAw0EzxEREzUJPBsROYX5meV7ZNZR1w1sSEpHnA54E32b5not32zvL9Z8A1FIfEIiLiEGkyODYAiyUtkjQHWAGMVheQtLgy+Wrg7rL96cCXgYtt/31l+SMkHVd+fhLwGuB7DW5DRERM0thVVbZ3S1pFcUXUbOBy27dLugQYsz0KrJJ0OvA48BBwXrn6KuB5wPskva9s+13gn4EbytCYDdwIfKKpbYiIiH3Jdq9raFyr1fLYWK7ejYioQ9JG263J7bUPVUl6hqTf6E5ZERFxuOkoOMq7tY+RdCzwj8AnJF3WbGkR0ZdGRmBwEGbNKt5HRnpdURxine5xPK28We+1wFW2Xwyc3lxZEdGXRkZg5UrYtg3s4n3lyoTHDNNpcBwh6Xjg9cCXGqwnIvrZ6tWwa9febbt2Fe0xY3QaHJdQXB21xfYGSc+hvHQ2ImaQ7dvrtce01NHluLavA66rTG+leBRIRMwkCxYUh6fatceMsd/gkPSHti+V9FHKBxBW2W73bKmImK7WrCnOaVQPV82dW7THjHGgPY47yvfcBBERMDRUvK9eXRyeWrCgCI2J9pgROroBUNJRth+Z1Hac7R82VlkX5QbAiIj6nugNgN+R9FuVzs4G/qFbxUVExOGj0+AYAj4q6YOSRoC3AqcdYJ2IeKJys130oU6vqrpN0hrgauBnwEts72i0soiZbuJmu4kT0RM320HOKURPdfrIkU8C/xn4DeAtwJckvbPJwiJmvNxsF32q00NVtwEvt32v7RuAFwMvbK6siMjNdtGvOgoO2//blcuvbP/E9vnNlRURU95Ul5vtosc6PVS1WNLnJG2WtHXi1XRxETPamjXFzXVVudku+kCnh6quAP4C2A28HLgK+PSBVpK0TNKdkrZIurjN/Ask3SZpk6RvSlpSmfeecr07Jb2i0z4jpo2hIRgehoULQSreh4dzYjx6rtMbADfa/k1Jt9k+qdq2n3VmA3cBZwA7KMYgP8f25soyx5SPa0fScuAdtpeVAfIZ4BTg2RRDxJ5YrrbfPtvJDYAREfVNdQNgp2OOPyppFnB3OY74TuDoA6xzCsXTdLeWBawDzgR++SU/ERqlp7DneVhnAutsPwrcK2lL2R8H6jMiIprVaXD8PjAXeBfwSeBh4LwDrHMCcF9legfF1Vh7KS/rvRCYw56bCk8A1k9a94Ty8wH7LPtdCawEWJCTiRERXdPpVVUbbD9c3vQ3YPts2+sPuGJnfa+1/VzgIuC93eiz7HfYdst2a2BgoFvdRkTMeJ3ucVSpw+V2AvMr0/PKtqmsozgBf6B16/QZERFd1ulVVVWf6HC5DcBiSYskzQFWAKPVBSQtrky+mj2jCo4CKyQdKWkRsBj4Tid9RkREs2rvcdj+Px0ut7s8kX4DMBu43Pbtki4BxmyPAqsknQ48DjxEed6kXO6zFCe9dwPvtP1zgHZ91t2GiIg4eB1djnu4y+W4ERH1PdHxOCIiIoAER0RE1JTgiIiIWhIcERFRS4IjIiJqSXBEREQtCY6IiKglwRHR70ZGYHAQZs0q3kdGel1RzHAH86yqiDhURkZg5UrYtauY3ratmIYM6BQ9kz2OiH62evWe0Jiwa1fRHtEjCY6IfrZ9e732iEMgwRHRz6YahCyDk0UPJTgi+tmaNTB37t5tc+cW7RE9kuCI6GdDQzA8DAsXglS8Dw/nxHj0VK6qiuh3Q0MJiugr2eOIiIhaGg0OScsk3Slpi6SL28y/UNJmSbdK+pqkhWX7yyVtqrwekXRWOe9KSfdW5i1tchsiImJvjR2qkjQbWAucAewANkgatb25stgtQMv2LklvBy4F3mD7JmBp2c+xwBbgq5X1/qvtzzVVe0RETK3JPY5TgC22t9p+DFgHnFldwPZNtifubloPzGvTz+uA6yvLRUREDzUZHCcA91Wmd5RtUzkfuL5N+wrgM5Pa1pSHtz4k6ch2nUlaKWlM0tj4+HiduiMiYj/64uS4pHOBFvDBSe3HAycBN1Sa3wP8GvAi4FjgonZ92h623bLdGhgYaKTuiIiZqMng2AnMr0zPK9v2Iul0YDWw3Pajk2a/Hvi87ccnGmw/4MKjwBUUh8QiIuIQaTI4NgCLJS2SNIfikNNodQFJJwMfpwiNB9v0cQ6TDlOVeyFIEnAW8L0Gao+IiCk0dlWV7d2SVlEcZpoNXG77dkmXAGO2RykOTR0NXFfkANttLweQNEixx/K3k7oekTQACNgEXNDUNkRExL5ku9c1NK7VanlsbKzXZcShMjJSPHZ8+/biYYBr1uTO64iDIGmj7dbk9r44OR59YLqMMjcx8NG2bWDvGfjocN2eiD6U4Ijp9WWbgY8iGpfgiOn1ZZuBjyIal+CI6fVlm4GPIhqX4Ijp9WWbgY8iGpfgiOn1ZZuBjyIal4GcYs+X6nS5hDUDH0U0KsERhXzZRkSHcqgqIiJqSXBEREQtCY6IiKglwREREbUkOCIiopYER0RE1JLgiIiIWhIcERFRS6PBIWmZpDslbZF0cZv5F0raLOlWSV+TtLAy7+eSNpWv0Ur7IknfLvu8thyWNiIiDpHGgkPSbGAt8EpgCXCOpCWTFrsFaNn+DeBzwKWVef9ie2n5Wl5p/wDwIdvPAx4Czm9qGyIiYl9N7nGcAmyxvdX2Y8A64MzqArZvsj0xEMR6YN7+OlQxMPlpFCED8CngrK5WHRER+9VkcJwA3FeZ3lG2TeV84PrK9FGSxiStlzQRDs8Efmx794H6lLSyXH9sfHz84LYgIiL20RcPOZR0LtACXlppXmh7p6TnAF+XdBvwk077tD0MDAO0Wi13s96IiJmsyT2OncD8yvS8sm0vkk4HVgPLbT860W57Z/m+FbgZOBn4EfB0SROB17bPiIhoTpPBsQFYXF4FNQdYAYxWF5B0MvBxitB4sNL+DElHlp+PA/4tsNm2gZuA15WLngd8scFtiIiISRoLjvI8xCrgBuAO4LO2b5d0iaSJq6Q+CBwNXDfpstvnA2OSvksRFP/L9uZy3kXAhZK2UJzz+GRT2xAREftS8Uv89NZqtTw2NtbrMiIiDiuSNtpuTW7PnePT0cgIDA7CrFnF+8hIryuKiGmkL66qii4aGYGVK2FXeXvMtm3FNGRo2IjoiuxxTDerV+8JjQm7dhXtERFdkOCYbrZvr9ceEVFTgmO6WbCgXntERE0JjulmzRqYO3fvtrlzi/aIiC5IcEw3Q0MwPAwLF4JUvA8P58R4RHRNrqqajoaGEhQR0ZjscURERC0JjoiIqCXBMZXcfR0R0VbOcbSTu68jIqaUPY52cvd1RMSUEhzt5O7riIgpJTjayd3XERFTSnC0k7uvIyKm1GhwSFom6U5JWyRd3Gb+hZI2S7pV0tckLSzbl0r6lqTby3lvqKxzpaR7yxEDN0la2vXCc/d1RMSUGhsBUNJs4C7gDGAHxRjk51SGgEXSy4Fv294l6e3Ay2y/QdKJgG3fLenZwEbg+bZ/LOlK4Eu2P9dpLRkBMCKivl6MAHgKsMX2VtuPAeuAM6sL2L7J9sTlS+uBeWX7XbbvLj/fDzwIDDRYa0REdKjJ4DgBuK8yvaNsm8r5wPWTGyWdAswB7qk0rykPYX1I0pHtOpO0UtKYpLHx8fH61UdERFt9cXJc0rlAC/jgpPbjgauBt9j+Rdn8HuDXgBcBxwIXtevT9rDtlu3WwEB2ViIiuqXJ4NgJzK9Mzyvb9iLpdGA1sNz2o5X2Y4AvA6ttr59ot/2AC48CV1AcEouIiEOkyeDYACyWtEjSHGAFMFpdQNLJwMcpQuPBSvsc4PPAVZNPgpd7IUgScBbwvQa3ISIiJmnsWVW2d0taBdwAzAYut327pEuAMdujFIemjgauK3KA7baXA68HXgI8U9Kbyy7fbHsTMCJpABCwCbigqW2IiIh9NXY5bj/J5bgREfX14nLciIiYhhIcERFRS4IjIiJqSXBEREQtCY6IiKglwVFHxiGPiMiY4x3LOOQREUD2ODqXccgjIoAER+cyDnlEBJDg6FzGIY+IABIcncs45BERQIKjcxmHPCICyFVV9QwNJSgiYsbLHkdERNSS4IiIiFoSHBERUUuCIyIiaklwRERELTNi6FhJ48C2mqsdB/ywgXKeqH6sqx9rgv6sqx9rgv6sqx9rgv6sq6maFtoemNw4I4LjYEgaazfWbq/1Y139WBP0Z139WBP0Z139WBP0Z12HuqYcqoqIiFoSHBERUUuCY2rDvS5gCv1YVz/WBP1ZVz/WBP1ZVz/WBP1Z1yGtKec4IiKiluxxRERELQmOiIioJcFRknSspL+RdHf5/owplrtU0u2S7pD0EUnqk7oWSPpqWddmSYO9rqlc9hhJOyT9eVP11KlL0lJJ3yp/hrdKekNDtSyTdKekLZIubjP/SEnXlvO/3eTPq0ZNF5b/dm6V9DVJC5uuqZO6KsudLcmSDsllp53UJen15d/Z7ZKu6XVN5ffATZJuKX+Or2qkENt5Fed5LgUuLj9fDHygzTL/Bvh7YHb5+hbwsl7XVc67GTij/Hw0MLfXNZXzPwxcA/x5n/wMTwQWl5+fDTwAPL3LdcwG7gGeA8wBvgssmbTMO4CPlZ9XANc2/HfTSU0vn/h3A7y96Zo6ratc7qnAN4D1QKsf6gIWA7cAzyinf6UPahoG3l5+XgJ8v4lassexx5nAp8rPnwLOarOMgaMofmhHAk8CftDruiQtAY6w/TcAth+2vauXNZV1/SbwLOCrDdZSqy7bd9m+u/x8P/AgsM+dsU/QKcAW21ttPwasK2ubqtbPAb/T8N7rAWuyfVPl3816YF6D9XRcV+mPgQ8AjxyCmjqt663AWtsPAdh+sA9qMnBM+flpwP1NFJLg2ONZth8oP/8TxRfeXmx/C7iJ4rfUB4AbbN/R67oofov+saS/KndRPyhpdi9rkjQL+DPg3Q3WUbuuKkmnUPwScE+X6zgBuK8yvaNsa7uM7d3AT4BndrmOujVVnQ9c32A9Ew5Yl6QXAvNtf/kQ1NNxXRT/706U9PeS1kta1gc1vR84V9IO4CvAf2qikBk1AqCkG4FfbTNrdXXCtiXtc52ypOcBz2fPb2J/I+lU23/Xy7oofo6nAicD24FrgTcDn+xhTe8AvmJ7Rzd/ke5CXRP9HA9cDZxn+xddK3AakHQu0AJe2ge1zAIuo/j33G+OoDhc9TKK74RvSDrJ9o97WNM5wJW2/0zSbwNXS3pBt/+Nz6jgsH36VPMk/UDS8bYfKL9U2u12/jtgve2Hy3WuB34beELB0YW6dgCbbG8t1/kC8Fs8geDoQk2/DZwq6R0U51zmSHrY9pQnPw9RXUg6BvgysNr2+idSzxR2AvMr0/PKtnbL7JB0BMVhhR81UEudmpB0OkUIv9T2ow3W02ldTwVeANxc/gLyq8CopOW2x3pYFxT/775t+3HgXkl3UQTJhh7WdD6wDIojJJKOongAYlcPo+VQ1R6jwHnl5/OAL7ZZZjvwUklHSHoSxW9kTR+q6qSuDcDTJU0cqz8N2NzLmmwP2V5ge5DicNVVTzQ0ulGXpDnA58t6PtdQHRuAxZIWlX/eirK2qWp9HfB1l2c0e1WTpJOBjwPLD8Hx+o7qsv0T28fZHiz/La0v62syNA5YV+kLFHsbSDqO4tDV1h7XtB34nbKm51Ockx3veiVNXgVwOL0oji9/DbgbuBE4tmxvAf/Xe65q+DhFWGwGLuuHusrpM4BbgduAK4E5va6psvybOTRXVXXyMzwXeBzYVHktbaCWVwF3UZw/WV22XULxpQfFf+jrgC3Ad4DnHIK/nwPVdCPFxR4Tfy+jTdfUSV2Tlr2ZQ3BVVYd/X6I4jLa5/H+3og9qWkJx5ed3y5/h7zZRRx45EhERteRQVURE1JLgiIiIWhIcERFRS4IjIiJqSXBEREQtCY6IPiXpAklv6nUdEZPlctyIiKglexwRXSDpReX4B0dJeko5PsMLJi3ze+XYG7dIulHSs8r2D0t6X/n5FZK+IWmWpPdLenfZ/q7KWBnrDv0WRuyRPY6ILpH0JxR3hD8Z2GH7f06a/wzgx7Yt6T8Cz7f9B5LmUjxOYhXwMeBVtu+R9H7gYdt/Kul+YJHtRyU93b19kF7McDPqIYcRDbuEIgAeAd7VZv484NryAYxzgHsBbO+S9FaKgYr+i+12j3m/FRgpH2D5hSaKj+hUDlVFdM8zKZ4E/FTgKElrJG2StKmc/1GKZ3adBLyNYu9kwkkUT8d99hR9vxpYC7wQ2FA+UTeiJxIcEd3zceCPgBGKYWtX215qe2k5/2nseQz2xJNxUTG29x9QjKfySkkvrnZajkkx3/ZNwEVlP0c3uiUR+5HfWiK6oLxs9nHb15SjL/6DpNNsf72y2PuB6yQ9BHwdWFQOF/tJ4N2275d0PnClpBdV1psNfFrS0yieyPqRnOOIXsrJ8YiIqCWHqiIiopYER0RE1JLgiIiIWhIcERFRS4IjIiJqSXBEREQtCY6IiKjl/wMJoJIb0ZiE/wAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradient Descent로 Linear Regression (K-fold cross validation)"
      ],
      "metadata": {
        "id": "uDAEAcoPUj1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data shaping\n",
        "if len(x_data.shape)==1 and len(y_data.shape)==1:\n",
        "  x_data= np.expand_dims(x_data, axis=-1)\n",
        "  y_data= np.expand_dims(y_data, axis=-1)\n",
        "print(x_data.shape, y_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAG2KJnDUfB-",
        "outputId": "d9867f1a-65c6-4b9e-9ba5-603fa8504268"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 1) (10, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyper-parameters\n",
        "input_size = 1\n",
        "output_size = 1\n",
        "num_epochs = 100\n",
        "learning_rate = 0.1\n",
        "K = 5\n",
        "n_over_k = int(len(x_data)/K)\n",
        "\n",
        "val_losses = [] # array for saving validation losses\n",
        "\n",
        "for k in range(K):\n",
        "  # Linear regression model, y = Wx + b\n",
        "  model = nn.Linear(input_size, output_size)\n",
        "\n",
        "  # Loss and optimizer\n",
        "  criterion = nn.MSELoss()\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  # training / validation partition of the k-th round\n",
        "  # np.delete 함수에 slice를 넘겨주면 해당 axis의 해당 인덱스들을 array에서 제거\n",
        "  # k번 반복할 때마다 train이랑 valid를 바꿔줘야하기 때문에\n",
        "  x_train = np.delete(x_data, slice(k*n_over_k, (k+1)*n_over_k), axis=0) # axis=0은 1은 열\n",
        "  y_train = np.delete(y_data, slice(k*n_over_k, (k+1)*n_over_k), axis=0)\n",
        "\n",
        "  # 앞 뒤로 slice 한 것을 첫 번째 axis를 기준으로 붙여도 됨(concatenate 함수)\n",
        "  # x_train = np.concatenate((x_data[:k*n_over_k,:], x_data[(k+1)*n_over_k:,:]), axis=0)\n",
        "  # y_train = np.concatenate((y_data[:k*n_over_k,:], y_data[(k+1)*n_over_k:,:]), axis=0)\n",
        "\n",
        "  x_valid = x_data[k*n_over_k:(k+1)*n_over_k, :]\n",
        "  y_valid = y_data[k*n_over_k:(k+1)*n_over_k, :]\n",
        "\n",
        "  # Train the model\n",
        "  for epoch in range(num_epochs):\n",
        "    # Convert numpy arrays to torch tensors\n",
        "    inputs = torch.from_numpy(x_train)\n",
        "    targets = torch.from_numpy(y_train)\n",
        "\n",
        "    # Predict outputs with the linear model.\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, targets)\n",
        "\n",
        "    # compute gradients and update\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 20 == 0:\n",
        "      print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
        "    \n",
        "  # validation error\n",
        "  inputs = torch.from_numpy(x_valid)\n",
        "  targets = torch.from_numpy(y_valid)\n",
        "  outputs = model(inputs)\n",
        "  loss = criterion(outputs, targets)\n",
        "  print(k+1, \"-th round validation error: \", loss.item())\n",
        "  val_losses.append(loss.item())\n",
        "\n",
        "val_losses = np.asarray(val_losses)\n",
        "print(\"Final validation error: \", val_losses.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRU798trU1Iw",
        "outputId": "685ab1a9-9c0c-4d73-c726-cc03f5877296"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20/100], Loss: 0.0009\n",
            "Epoch [40/100], Loss: 0.0002\n",
            "Epoch [60/100], Loss: 0.0002\n",
            "Epoch [80/100], Loss: 0.0002\n",
            "Epoch [100/100], Loss: 0.0002\n",
            "1 -th round validation error:  8.724959479877725e-05\n",
            "Epoch [20/100], Loss: 0.0311\n",
            "Epoch [40/100], Loss: 0.0039\n",
            "Epoch [60/100], Loss: 0.0007\n",
            "Epoch [80/100], Loss: 0.0003\n",
            "Epoch [100/100], Loss: 0.0002\n",
            "2 -th round validation error:  2.274244798172731e-05\n",
            "Epoch [20/100], Loss: 0.0006\n",
            "Epoch [40/100], Loss: 0.0002\n",
            "Epoch [60/100], Loss: 0.0001\n",
            "Epoch [80/100], Loss: 0.0001\n",
            "Epoch [100/100], Loss: 0.0001\n",
            "3 -th round validation error:  0.000427857885370031\n",
            "Epoch [20/100], Loss: 0.0342\n",
            "Epoch [40/100], Loss: 0.0036\n",
            "Epoch [60/100], Loss: 0.0005\n",
            "Epoch [80/100], Loss: 0.0002\n",
            "Epoch [100/100], Loss: 0.0002\n",
            "4 -th round validation error:  0.0002834916231222451\n",
            "Epoch [20/100], Loss: 0.0269\n",
            "Epoch [40/100], Loss: 0.0044\n",
            "Epoch [60/100], Loss: 0.0008\n",
            "Epoch [80/100], Loss: 0.0002\n",
            "Epoch [100/100], Loss: 0.0001\n",
            "5 -th round validation error:  0.0010093249147757888\n",
            "Final validation error:  0.00036613329320971387\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = open('/content/drive/MyDrive/Colab Notebooks/data/regression_data.txt','r')  # open the file with read-only\n",
        "text = file.readlines()  # read all line texts\n",
        "file.close()  # close the file\n",
        "\n",
        "x_data = []\n",
        "y_data = []\n",
        "\n",
        "# convert to float\n",
        "for s in text:\n",
        "    data = s.split()\n",
        "    x_data.append(float(data[0]))\n",
        "    y_data.append(float(data[1]))    \n",
        "\n",
        "# convert to numpy-array\n",
        "x_data = np.asarray(x_data, dtype=np.float32)\n",
        "y_data = np.asarray(y_data, dtype=np.float32)"
      ],
      "metadata": {
        "id": "lSKrt8A1dD_V"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data shaping\n",
        "if len(x_data.shape)==1 and len(y_data.shape)==1:\n",
        "  x_data = np.expand_dims(x_data, axis=-1)\n",
        "  y_data = np.expand_dims(y_data, axis=-1)\n",
        "print(x_data.shape, y_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqUfwUCOgDiO",
        "outputId": "e491b012-ee3f-4b1d-f9c6-3ae6c670a069"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 1) (100, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyper-parameters\n",
        "input_size = 1\n",
        "ouput_size = 1\n",
        "num_epochs = 100\n",
        "learning_rate = 0.1\n",
        "K = 5\n",
        "n_over_k = int(len(x_data)/K)\n",
        "\n",
        "val_losses = [] # array for saving validation losses\n",
        "\n",
        "for k in range(K):\n",
        "  # Linear regression model, y = Wx + b\n",
        "  model = nn.Linear(input_size, output_size)\n",
        "\n",
        "  # Loss and optimizer\n",
        "  criterion = nn.MSELoss()\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  # training / validation partition of the k-th round\n",
        "  # np.delete 함수에 slice를 넘겨주면 해당 axis의 해당 인덱스들을 array에서 제거\n",
        "  # k번 반복할 때마다 train이랑 valid를 바꿔줘야하기 때문에\n",
        "  x_train = np.delete(x_data, slice(k*n_over_k, (k+1)*n_over_k), axis=0)\n",
        "  y_train = np.delete(y_data, slice(k*n_over_k, (k+1)*n_over_k), axis=0)\n",
        "\n",
        "  # 앞 뒤로 slice 한 것을 첫 번째 axis를 기준으로 붙여도 됨(concatenate 함수)\n",
        "  # x_tarin = np.concatenate((x_data[:k*n_over_k,:], x_data[(k+1)*n_oevr_k]), axis=0)\n",
        "  # y_tarin = np.concatenate((y_data[:k*n_over_k,:], y_data[(k+1)*n_oevr_k]), axis=0)\n",
        "\n",
        "  x_valid = x_data[k*n_over_k:(k+1)*n_over_k, :]\n",
        "  y_valid = y_data[k*n_over_k:(k+1)*n_over_k, :]\n",
        "\n",
        "  # Train the model\n",
        "  for epoch in range(num_epochs):\n",
        "    # Convert numpy arrays to torch tensors\n",
        "    inputs = torch.from_numpy(x_train)\n",
        "    targets = torch.from_numpy(y_train)\n",
        "\n",
        "    # Predict outputs with the linear model.\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, targets)\n",
        "\n",
        "    # compute gradients and update\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 20 == 0:\n",
        "      print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
        "\n",
        "  # validation error\n",
        "  inputs = torch.from_numpy(x_valid)\n",
        "  targets = torch.from_numpy(y_valid)\n",
        "  output = model(inputs)\n",
        "  loss = criterion(outputs, targets)\n",
        "  print(k+1, \"-th round validation error: \", loss.item())\n",
        "  val_losses.append(loss.item())\n",
        "\n",
        "val_losses = np.asarray(val_losses)\n",
        "print(\"Final validation error: \", val_losses.mean())"
      ],
      "metadata": {
        "id": "iuxMVl8-hLIQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}